{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd32179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe53e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Dataset pour le débruitage\n",
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.image_paths = [\n",
    "            os.path.join(root_dir, img) for img in os.listdir(root_dir)\n",
    "            if img.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))\n",
    "        ]\n",
    "        if not self.image_paths:\n",
    "            raise ValueError(f\"Aucune image valide trouvée dans le répertoire: {root_dir}\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def add_gaussian_noise(self, image, mean=0, std=0.3):\n",
    "        noise = torch.randn_like(image) * std + mean\n",
    "        return torch.clamp(image + noise, 0, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        noisy_image = self.add_gaussian_noise(image)\n",
    "        return noisy_image, image\n",
    "\n",
    "\n",
    "# Transformations pour le dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Chargement du dataset BSD500\n",
    "train_dataset = DenoisingDataset(root_dir='archive/images/train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5859c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du générateur (CGNet)\n",
    "class CGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CGNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Définition du discriminateur\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=0),\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = torch.mean(x, dim=(2, 3))  # Global average pooling\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21175213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des modèles\n",
    "generator = CGNet().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Critères et optimiseurs\n",
    "pixelwise_loss = nn.MSELoss()\n",
    "adversarial_loss = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Entraînement\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    for noisy_imgs, clean_imgs in tqdm(train_loader):\n",
    "        noisy_imgs = noisy_imgs.to(device)\n",
    "        clean_imgs = clean_imgs.to(device)\n",
    "\n",
    "        # Labels pour le discriminateur\n",
    "        batch_size = noisy_imgs.size(0)\n",
    "        valid = torch.ones((batch_size, 1), device=device, requires_grad=False)\n",
    "        fake = torch.zeros((batch_size, 1), device=device, requires_grad=False)\n",
    "\n",
    "        # ----- Mise à jour du générateur -----\n",
    "        optimizer_G.zero_grad()\n",
    "        generated_imgs = generator(noisy_imgs)\n",
    "        g_loss_pixelwise = pixelwise_loss(generated_imgs, clean_imgs)\n",
    "        g_loss_adversarial = adversarial_loss(discriminator(generated_imgs), valid)\n",
    "        g_loss = 0.001 * g_loss_adversarial + g_loss_pixelwise\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ----- Mise à jour du discriminateur -----\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(clean_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Generator Loss: {g_loss.item():.4f} | Discriminator Loss: {d_loss.item():.4f}\")\n",
    "\n",
    "# Sauvegarde des modèles\n",
    "torch.save(generator.state_dict(), 'generator.pth')\n",
    "torch.save(discriminator.state_dict(), 'discriminator.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour appliquer plusieurs cycles de fermeture et ouverture sur chaque composante RGB\n",
    "def apply_multiple_morphology_operations(generated_image, iterations=20):\n",
    "    generated_np = generated_image.permute(1, 2, 0).cpu().numpy() * 255\n",
    "    transformed_np = np.copy(generated_np)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for i in range(3):\n",
    "            channel = transformed_np[:, :, i].astype(np.uint8)\n",
    "            channel_closed = cv2.morphologyEx(channel, cv2.MORPH_CLOSE, kernel)\n",
    "            channel_opened = cv2.morphologyEx(channel_closed, cv2.MORPH_OPEN, kernel)\n",
    "            transformed_np[:, :, i] = channel_opened\n",
    "\n",
    "    return torch.tensor(transformed_np / 255.0).permute(2, 0, 1)\n",
    "\n",
    "\n",
    "# Fonction pour fusionner avec les hautes fréquences\n",
    "def fuse_with_high_frequencies(base_image, refined_image):\n",
    "    base_np = base_image.permute(1, 2, 0).cpu().numpy() * 255\n",
    "    refined_np = refined_image.permute(1, 2, 0).cpu().numpy() * 255\n",
    "\n",
    "    refined_blur = cv2.GaussianBlur(refined_np, (5, 5), 0)\n",
    "    high_freq = refined_np - refined_blur\n",
    "    fused_np = np.clip(base_np + high_freq, 0, 255)\n",
    "\n",
    "    return torch.tensor(fused_np / 255.0).permute(2, 0, 1)\n",
    "\n",
    "\n",
    "# Fonction pour détecter les contours avec Canny\n",
    "def detect_canny_edges(image):\n",
    "    image_np = image.permute(1, 2, 0).cpu().numpy() * 255\n",
    "    image_gray = cv2.cvtColor(image_np.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(image_gray, threshold1=100, threshold2=200)\n",
    "    return torch.tensor(edges / 255.0).unsqueeze(0)\n",
    "\n",
    "\n",
    "# Fonction d'affichage\n",
    "def show_sample_with_metrics(generator, dataset, index, iterations=3):\n",
    "    generator.eval()\n",
    "\n",
    "    noisy_img, clean_img = dataset[index]\n",
    "    noisy_img = noisy_img.unsqueeze(0).to(device)\n",
    "    clean_img = clean_img.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_img = generator(noisy_img)\n",
    "\n",
    "    refined_img = apply_multiple_morphology_operations(generated_img.squeeze(), iterations=iterations)\n",
    "    fused_img = fuse_with_high_frequencies(generated_img.squeeze(), refined_img)\n",
    "\n",
    "    noisy_edges = detect_canny_edges(noisy_img.squeeze())\n",
    "    clean_edges = detect_canny_edges(clean_img.squeeze())\n",
    "    generated_edges = detect_canny_edges(generated_img.squeeze())\n",
    "    refined_edges = detect_canny_edges(refined_img)\n",
    "    fused_edges = detect_canny_edges(fused_img)\n",
    "\n",
    "    # Calcul des PSNR\n",
    "    psnr_noisy = psnr(clean_img.squeeze().permute(1, 2, 0).cpu().numpy(), noisy_img.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    psnr_generated = psnr(clean_img.squeeze().permute(1, 2, 0).cpu().numpy(), generated_img.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    psnr_refined = psnr(clean_img.squeeze().permute(1, 2, 0).cpu().numpy(), refined_img.permute(1, 2, 0).cpu().numpy())\n",
    "    psnr_fused = psnr(clean_img.squeeze().permute(1, 2, 0).cpu().numpy(), fused_img.permute(1, 2, 0).cpu().numpy())\n",
    "\n",
    "    print(f\"PSNR Noisy: {psnr_noisy:.2f}, PSNR Generated: {psnr_generated:.2f}, PSNR Refined: {psnr_refined:.2f}, PSNR Fused: {psnr_fused:.2f}\")\n",
    "\n",
    "    plt.figure(figsize=(20, 16))\n",
    "\n",
    "    images = [\n",
    "        (noisy_img, noisy_edges, \"Noisy Image\"),\n",
    "        (clean_img, clean_edges, \"Clean Image\"),\n",
    "        (generated_img, generated_edges, \"Generated Image\"),\n",
    "        (refined_img, refined_edges, \"Refined Image\"),\n",
    "        (fused_img, fused_edges, \"Fused Image\"),\n",
    "    ]\n",
    "\n",
    "    for i, (image, edge, title) in enumerate(images):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.title(title)\n",
    "        plt.imshow(image.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(2, 5, i + 6)\n",
    "        plt.title(f\"{title} Edges\")\n",
    "        plt.imshow(edge.squeeze().cpu().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Exemple d'affichage\n",
    "for idx in range(5):  # Affiche les 5 premiers échantillons\n",
    "    show_sample_with_metrics(generator, train_dataset, idx, iterations=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
