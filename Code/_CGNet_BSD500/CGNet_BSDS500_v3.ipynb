{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd32179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIMAModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NIMAModel, self).__init__()\n",
    "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V2')\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.base_model.last_channel, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "nima_model = NIMAModel().to(device)\n",
    "nima_model.eval()\n",
    "\n",
    "def calculate_nima_score(image_tensor):\n",
    "    with torch.no_grad():\n",
    "        scores = nima_model(image_tensor.unsqueeze(0).to(device))\n",
    "        scores = torch.softmax(scores, dim=1)\n",
    "        return torch.sum(scores * torch.arange(1, 11).to(device)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Forcer l'installation de nbformat dans l'environnement actuel du notebook\n",
    "!{sys.executable} -m pip install --upgrade nbformat\n",
    "\n",
    "import nbformat\n",
    "import zipfile\n",
    "\n",
    "def clear_notebook_output(notebook_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Nettoyer toutes les sorties d'un notebook Jupyter pour le rendre plus l√©ger.\n",
    "    \"\"\"\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "\n",
    "    for cell in notebook.cells:\n",
    "        if 'outputs' in cell:\n",
    "            cell['outputs'] = []\n",
    "        if 'execution_count' in cell:\n",
    "            cell['execution_count'] = None\n",
    "\n",
    "\n",
    "    output_path = output_path or notebook_path\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(notebook, f)\n",
    "    print(f\"Nettoyage termin√© ! Notebook all√©g√© sauvegard√© sous : {output_path}\")\n",
    "\n",
    "def zip_notebook(notebook_path):\n",
    "    \"\"\"\n",
    "    Compresser le notebook nettoy√© pour r√©duire sa taille.\n",
    "    \"\"\"\n",
    "    zip_path = notebook_path.replace(\".ipynb\", \".zip\")\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipf.write(notebook_path)\n",
    "    print(f\"Notebook compress√© et sauvegard√© sous : {zip_path}\")\n",
    "\n",
    "def delete_large_files():\n",
    "    \"\"\"\n",
    "    Supprimer tous les fichiers volumineux tels que .pth, .h5 et les checkpoints.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(\".\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pth\") or file.endswith(\".h5\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                os.remove(file_path)\n",
    "                print(f\"Fichier supprim√© : {file_path}\")\n",
    "\n",
    "\n",
    "    if os.path.exists('.ipynb_checkpoints'):\n",
    "        os.system(\"rm -rf .ipynb_checkpoints\")\n",
    "        print(\"Checkpoints supprim√©s.\")\n",
    "\n",
    "    print(\"Nettoyage des fichiers volumineux termin√© !\")\n",
    "\n",
    "notebook_name = \"CGNet_BSD500_complet.ipynb\"\n",
    "\n",
    "\n",
    "clear_notebook_output(notebook_name, \"notebook_all√©g√©.ipynb\")\n",
    "zip_notebook(\"notebook_all√©g√©.ipynb\")\n",
    "delete_large_files()\n",
    "\n",
    "print(\"\\nüì¶ Op√©rations termin√©es ! Le notebook a √©t√© nettoy√©, compress√© et les fichiers inutiles supprim√©s.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d303090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from scipy.ndimage import median_filter\n",
    "from bm3d import bm3d\n",
    "\n",
    "\n",
    "# Configuration du p√©riph√©rique\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Dataset pour le d√©bruitage\n",
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.image_paths = [\n",
    "            os.path.join(root_dir, img) for img in os.listdir(root_dir)\n",
    "            if img.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))\n",
    "        ]\n",
    "        if not self.image_paths:\n",
    "            raise ValueError(f\"Aucune image valide trouv√©e dans le r√©pertoire: {root_dir}\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def add_gaussian_noise(self, image, mean=0, std=0.3):\n",
    "        noise = torch.randn_like(image) * std + mean\n",
    "        return torch.clamp(image + noise, 0, 1)\n",
    "\n",
    "    def add_salt_pepper_noise(self, image, prob=0.08):\n",
    "        noisy_image = image.clone()\n",
    "        num_pixels = image.shape[1] * image.shape[2]\n",
    "        num_pepper = int(prob * num_pixels * 0.5)\n",
    "        pepper_coords = (torch.randint(0, image.shape[1], (num_pepper,)),\n",
    "                         torch.randint(0, image.shape[2], (num_pepper,)))\n",
    "        noisy_image[:, pepper_coords[0], pepper_coords[1]] = 0\n",
    "        num_salt = int(prob * num_pixels * 0.5)\n",
    "        salt_coords = (torch.randint(0, image.shape[1], (num_salt,)),\n",
    "                       torch.randint(0, image.shape[2], (num_salt,)))\n",
    "        noisy_image[:, salt_coords[0], salt_coords[1]] = 1\n",
    "        return noisy_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Ajout de bruit (al√©atoire)\n",
    "        if np.random.rand() > 0.5:\n",
    "            noisy_image = self.add_gaussian_noise(image)\n",
    "        else:\n",
    "            noisy_image = self.add_salt_pepper_noise(image)\n",
    "\n",
    "        return noisy_image, image.float()  # Retourne l'image bruit√©e et l'image propre\n",
    "\n",
    "\n",
    "# Transformations pour le dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Chargement du dataset\n",
    "train_dataset = DenoisingDataset(root_dir='archive/images/train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "# D√©finition compl√®te du mod√®le CGNet\n",
    "class ContextGuidedBlock(nn.Module):\n",
    "    def __init__(self, nIn, nOut, dilation_rate=2):\n",
    "        super(ContextGuidedBlock, self).__init__()\n",
    "        self.conv1x1 = nn.Conv2d(nIn, nOut // 2, kernel_size=1)\n",
    "        self.conv3x3 = nn.Conv2d(nOut // 2, nOut, kernel_size=3, padding=dilation_rate, dilation=dilation_rate)\n",
    "        self.bn = nn.BatchNorm2d(nOut)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1x1(x)\n",
    "        x = self.conv3x3(x)\n",
    "        x = self.bn(x)\n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, nOut):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(nOut, nOut // 16, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(nOut // 16, nOut, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_map = self.attention(x)\n",
    "        return x * attention_map\n",
    "\n",
    "\n",
    "class CGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CGNet, self).__init__()\n",
    "        self.block1 = ContextGuidedBlock(3, 32)\n",
    "        self.block2 = ContextGuidedBlock(32, 64)\n",
    "        self.attention_block = AttentionBlock(64)\n",
    "        self.conv_final = nn.Conv2d(64, 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.block1(x)\n",
    "        x2 = self.block2(x1)\n",
    "        x3 = self.attention_block(x2)\n",
    "        output = self.conv_final(x3)\n",
    "        return output, x3\n",
    "\n",
    "\n",
    "# Entra√Ænement avec pr√©traitement utilis√© uniquement pour les m√©triques\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for noisy_imgs, clean_imgs in tqdm(train_loader):\n",
    "        noisy_imgs = noisy_imgs.to(device).float()\n",
    "        clean_imgs = clean_imgs.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(noisy_imgs)\n",
    "\n",
    "        # Calcul de la perte directement sur les sorties brutes\n",
    "        loss = criterion(outputs, clean_imgs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Pr√©traitement et PSNR (uniquement pour l'affichage ou l'√©valuation)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for noisy_imgs, clean_imgs in train_loader:\n",
    "            noisy_imgs = noisy_imgs.to(device).float()\n",
    "            clean_imgs = clean_imgs.to(device).float()\n",
    "            outputs, _ = model(noisy_imgs)\n",
    "\n",
    "            # Appliquer le pr√©traitement sur l'image d√©bruit√©e\n",
    "            preprocessed_images = []\n",
    "            for output in outputs:\n",
    "                output_np = output.detach().permute(1, 2, 0).cpu().numpy()\n",
    "                denoised_image = median_filter(output_np, size=3)  # Filtre m√©dian\n",
    "                preprocessed_image = torch.tensor(denoised_image).permute(2, 0, 1).to(device)\n",
    "                preprocessed_images.append(preprocessed_image)\n",
    "\n",
    "            preprocessed_images = torch.stack(preprocessed_images)\n",
    "            psnr_denoised = psnr(clean_imgs.cpu().numpy(), preprocessed_images.cpu().numpy())\n",
    "            print(f\"PSNR Denoised: {psnr_denoised:.2f}\")\n",
    "            break  # Affichage d'un seul batch pour chaque epoch\n",
    "\n",
    "\n",
    "# Sauvegarde du mod√®le\n",
    "torch.save(model.state_dict(), 'cgnet_full_preprocessed.pth')\n",
    "print(\"Mod√®le sauvegard√©.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Affichage des √©chantillons\n",
    "def show_sample_with_metrics(model, dataset, index):\n",
    "    \"\"\"\n",
    "    Affiche les images bruit√©es, originales et d√©bruit√©es avec PSNR.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    noisy_img, clean_img = dataset[index]\n",
    "    noisy_img = noisy_img.unsqueeze(0).to(device)\n",
    "    clean_img = clean_img.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(noisy_img)\n",
    "        output = output.cpu().squeeze()\n",
    "\n",
    "    psnr_noisy = psnr(clean_img.squeeze().permute(1, 2, 0).cpu().numpy(), noisy_img.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    psnr_denoised = psnr(clean_img.squeeze().permute(1, 2, 0).cpu().numpy(), output.permute(1, 2, 0).numpy())\n",
    "\n",
    "    print(f\"PSNR Noisy: {psnr_noisy:.2f}, PSNR Denoised: {psnr_denoised:.2f}\")\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Noisy Image\")\n",
    "    plt.imshow(noisy_img.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Clean Image\")\n",
    "    plt.imshow(clean_img.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Denoised Image\")\n",
    "    plt.imshow(output.permute(1, 2, 0).cpu().numpy())\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_sample_with_metrics(model, train_dataset, 0)\n",
    "show_sample_with_metrics(model, train_dataset, 1)\n",
    "show_sample_with_metrics(model, train_dataset, 2)\n",
    "show_sample_with_metrics(model, train_dataset, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d304e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'affichage\n",
    "show_sample_with_metrics(model, train_dataset, 0)\n",
    "show_sample_with_metrics(model, train_dataset, 1)\n",
    "show_sample_with_metrics(model, train_dataset, 2)\n",
    "show_sample_with_metrics(model, train_dataset, 3)\n",
    "show_sample_with_metrics(model, train_dataset, 4)\n",
    "show_sample_with_metrics(model, train_dataset, 5)\n",
    "show_sample_with_metrics(model, train_dataset, 6)\n",
    "show_sample_with_metrics(model, train_dataset, 7)\n",
    "show_sample_with_metrics(model, train_dataset, 8)\n",
    "show_sample_with_metrics(model, train_dataset, 9)\n",
    "show_sample_with_metrics(model, train_dataset, 10)\n",
    "show_sample_with_metrics(model, train_dataset, 11)\n",
    "show_sample_with_metrics(model, train_dataset, 12)\n",
    "show_sample_with_metrics(model, train_dataset, 13)\n",
    "show_sample_with_metrics(model, train_dataset, 14)\n",
    "show_sample_with_metrics(model, train_dataset, 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
